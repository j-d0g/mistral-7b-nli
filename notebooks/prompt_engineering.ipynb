{
 "cells": [
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('data/NLI_trial.csv')\n",
    "vanilla_1 = \"Your task is to solve NLI tasks. Given a premise and a hypothesis, you will determine whether the hypothesis entails (1) or doesn't entail (0) the premise. You should return your response as a JSON object with the 'label' key, containing the value 1 or 0. For example, {'label': 1}. You will not provide any other information in your response besides the valid JSON object containing only the predicted label.\"\n",
    "\n",
    "vanilla_2 = \"You are an AI assistant trained to classify the relationship between a given premise and hypothesis. Provide your prediction as a JSON object with the key 'label' and the value as either 0 (no entailment) or 1 (entailment). \"\n",
    "\n",
    "vanilla_3 = 'Your task is to determine if a given hypothesis is entailed by a premise. Output your prediction in the following JSON format: {\"label\": 0} for no entailment or {\"label\": 1} for entailment.'\n",
    "\n",
    "vanilla_4 = 'As an AI language model, your role is to classify the entailment relationship between a premise and a hypothesis. Provide your prediction in JSON format with the key \"label\" and the value as 0 or 1, where 0 indicates no entailment and 1 indicates entailment.'\n",
    "\n",
    "cot_1 = \"Your task is to solve NLI tasks. Given a premise and a hypothesis, you will determine whether the hypothesis entails (1) or doesn't entail (0) the premise. You can use any information you have to make your decision, which can be deduced from logical reasoning, entity recognition, or general common-sense. You should return your response as a json object with the key 'thoughts' to contain your logical reasoning and deduction steps, which should always be generated BEFORE the 'label' key which contains the prediction value 0 or 1. Do not provide any other information in your response besides the valid JSON object. For example, {'thoughts': 'your deductive/common-sense reasoning steps here', 'label': 0 or 1}.\"\n",
    "\n",
    "cot_2 = \"\"\"You are an expert in natural language reasoning and inference. Your task is to analyze pairs of sentences and determine if the second sentence (hypothesis) can be logically inferred from the first sentence (premise), while considering logical rules, common sense, and factual accuracy.\n",
    "\n",
    "For each example, I will provide the premise and hypothesis. Your response should be in the following JSON format:\n",
    "{\n",
    "    \"thought_process\": \n",
    "        [\n",
    "            \"step 1: <Identify key information and relationships in the premise, considering logical connections, commonsense understanding, and factual consistency>\",\n",
    "            \"step 2: <Analyze how the hypothesis relates to or contradicts the premise based on the information identified in Step 1. Evaluate if the hypothesis can be reasonably inferred from the premise>\",\n",
    "            \"step 3: <Explain your final reasoning and conclusion on whether the hypothesis is entailed by the premise or not>\"\n",
    "         ],\n",
    "    \"label\": \"<0 for no entailment, 1 for entailment>\"\n",
    "}\n",
    "Please provide a clear multi-step reasoning chain explaining how you arrived at your final answer, breaking it down into logical components. Ground your response in the given information, logical principles, common sense, and factual knowledge. Identify any inconsistencies or contradictions.\n",
    "\n",
    "Example:\n",
    "Premise: The dog chased the cat up the tree. Hypothesis: The cat climbed the tree.\n",
    "\n",
    "Your response:\n",
    "{\n",
    "  \"thought_process\": \"step 1: The premise indicates that the cat was chased up the tree by the dog, suggesting the cat climbed the tree. It is common sense that a cat would climb a tree to escape a chasing dog, and there are no known facts that contradict the premise or hypothesis. step 2: The hypothesis logically follows from the premise, as the cat climbing the tree is a reasonable consequence of being chased up the tree by the dog. step3: Based on the logical reasoning, common sense, and lack of contradictory facts, the hypothesis can be inferred from the premise.\"\n",
    "  \"label\": 1\n",
    "}\n",
    "\"\"\"\n",
    "\n",
    "cot_3 = \"\"\"You are an expert in natural language reasoning and inference. Your task is to analyze pairs of sentences and determine if the second sentence (hypothesis) can be logically inferred from the first sentence (premise), while considering logical rules, common sense, and factual accuracy.\n",
    "\n",
    "For each example, I will provide the premise and hypothesis. Your response should be in the following JSON format:\n",
    "{\n",
    "    \"thought_process\": \" \n",
    "    Step 1. <Analyze the premise, identifying key information, logical rules and connections.> \n",
    "    Step 2. <Use common-sense reasoning and world knowledge to verify consistency.> \n",
    "    Step 3. <Analyze the logical connections and contradictions between the premise and hypothesis. Evaluate if the hypothesis can be reasonably inferred from the premise>. \n",
    "    Step 4. <Explain your final reasoning and conclusion on whether the hypothesis is entailed by the premise or not>\",\n",
    "    \"label\": \"<0 for no entailment, 1 for entailment>\n",
    "    \"\n",
    "}\n",
    "Please provide a clear multi-step reasoning chain explaining how you arrived at your final answer, breaking it down into logical components. Ground your response in the given information, logical principles, common sense, and factual knowledge. Identify any inconsistencies or contradictions.\n",
    "\n",
    "Example:\n",
    "Premise: The dog chased the cat up the tree. Hypothesis: The cat climbed the tree.\n",
    "\n",
    "Your response:\n",
    "{\n",
    "  \"thought_process\": \"\n",
    "  Step 1.\n",
    "}\n",
    "\"\"\""
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-23T17:38:03.610777Z",
     "start_time": "2024-04-23T17:38:03.597701Z"
    }
   },
   "id": "5ce267f14582d563",
   "execution_count": 16
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "from service.prediction_service import predict_label\n",
    "from llm.mistral import Mistral\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "def generate_predictions(df, sys, file_path):\n",
    "    df['response_json'] = df.apply(lambda x: predict_label(sys, x['premise'], x['hypothesis'], Mistral(os.getenv('MISTRAL_API_KEY')), model_name='open-mistral-7b'), axis=1)\n",
    "    df['predicted_label'] = df['response_json'].apply(lambda x: x['label'])\n",
    "    # evaluate accuracy, precision, recall, f1\n",
    "    df['correct'] = df['predicted_label'] == df['label']\n",
    "    df['correct'].value_counts(normalize=True)\n",
    "    \n",
    "    df[['premise', 'hypothesis', 'label', 'predicted_label', 'correct', 'response_json']].to_csv(f'data/NLI_trial_predictions_{file_path}.csv', index=False)\n",
    "    \n",
    "    precision = df[df['correct'] == True].groupby('label').count()['correct'] / df.groupby('label').count()['correct']\n",
    "    recall = df[df['correct'] == True].groupby('label').count()['correct'] / df[df['correct'] == True].groupby('label').count()['correct'].sum()\n",
    "    accuracy = df['correct'].value_counts(normalize=True)[True]\n",
    "    f1 = 2 * (precision * recall) / (precision + recall)\n",
    "    \n",
    "    return precision, recall, accuracy, f1\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-23T17:05:20.653345Z",
     "start_time": "2024-04-23T17:05:20.590252Z"
    }
   },
   "id": "1477dabdf16c4dc3",
   "execution_count": 2
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
