{
  "dataset": {
    "train_examples": 37571,
    "dev_examples": 1977,
    "test_examples": 1974,
    "total_examples": 41522,
    "train_percentage": 90.48,
    "dev_percentage": 4.76,
    "test_percentage": 4.75,
    "label_distribution": {
      "entailment": 21429,
      "no_entailment": 20093,
      "entailment_percentage": 51.61,
      "no_entailment_percentage": 48.39
    }
  },
  "tokens": {
    "premise": {
      "avg": 26.87,
      "min": 0,
      "max": 340,
      "quartiles": [
        14.0,
        23.0,
        36.0
      ]
    },
    "hypothesis": {
      "avg": 14.51,
      "min": 0,
      "max": 71,
      "quartiles": [
        9.0,
        13.0,
        18.0
      ]
    },
    "thought_process": {
      "avg": 164.54,
      "min": 4,
      "max": 921,
      "quartiles": [
        125.0,
        153.0,
        191.0
      ]
    }
  },
  "models": {
    "Base_Mistral-7B": {
      "accuracy": 53.77,
      "precision": 60.49,
      "recall": 52.32,
      "f1_score": 41.51
    },
    "Mistral-7B-Instruct": {
      "accuracy": 76.0,
      "precision": 89.7,
      "recall": 57.2,
      "f1_score": 69.8
    },
    "Ablation0_Best": {
      "accuracy": 89.23,
      "precision": 89.21,
      "recall": 89.25,
      "f1_score": 89.22
    },
    "Ablation1_Best": {
      "accuracy": 89.58,
      "precision": 89.57,
      "recall": 89.58,
      "f1_score": 89.57
    },
    "Ablation2_Best": {
      "accuracy": 89.33,
      "precision": 89.38,
      "recall": 89.27,
      "f1_score": 89.30
    }
  },
  "token_vs_accuracy": {
    "ranges": [
      "0-100",
      "101-200",
      "201-300",
      "301+"
    ],
    "accuracies": [
      83.87096774193549,
      90.12265978050355,
      92.4,
      60.86956521739131
    ],
    "counts": [
      155,
      1549,
      250,
      23
    ]
  }
}